{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def getInfo(url) :\n",
    "    if(\"foxnews\" not in url):\n",
    "        return dict()\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    date = soup.find('time')['data-time-published']\n",
    "    articleHTML = soup.find('div', attrs={'class':'article-body'})\n",
    "\n",
    "\n",
    "    domain = url.split('/')[2]\n",
    "\n",
    "\n",
    "    hrefs = articleHTML.findAll('a')\n",
    "\n",
    "    sameHref = []\n",
    "    diffHrefs = []\n",
    "    domainRef=set()\n",
    "    for h in hrefs :\n",
    "        newHref = h['href']\n",
    "        print(newHref)\n",
    "        domainRef.add(newHref.split('/')[2])\n",
    "        if 'http' in newHref :\n",
    "            if 'foxnews' in  newHref :\n",
    "                sameHref += [newHref]\n",
    "            else :\n",
    "                diffHrefs += [newHref]\n",
    "\n",
    "\n",
    "    article = ''\n",
    "    ps = articleHTML.findAll('p')\n",
    "    for p in ps :\n",
    "        article += p.text +'\\n'\n",
    "    return {'sameHref':sameHref,'diffHrefs':diffHrefs, 'domainRef' : domainRef , 'date':str(date),'article':str(article)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-4b58087d7c3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://www.foxnews.com/travel/2018/02/24/ivanka-trump-flew-commercial-to-olympics.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# res = getInfo('totototo')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-982a68ca3ab6>\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mnewHref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewHref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mdomainRef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewHref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'http'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewHref\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'foxnews'\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mnewHref\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "res = getInfo('http://www.foxnews.com/travel/2018/02/24/ivanka-trump-flew-commercial-to-olympics.html')\n",
    "# res = getInfo('totototo')\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FirefoxWebElement' object has no attribute 'send_keysAndWait'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-2bc606b9e4f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://fakenewsai.com\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mcrawl_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-2bc606b9e4f5>\u001b[0m in \u001b[0;36mcrawl_url\u001b[0;34m(url, run_headless)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0minputUrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0minputUrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"www.foxnews.com\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0minputUrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keysAndWait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m#     time.sleep(2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mrealCalque\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"real\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FirefoxWebElement' object has no attribute 'send_keysAndWait'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from pyvirtualdisplay import Display\n",
    "import time\n",
    "\n",
    "def fakeNewsAI(domain)\n",
    "\n",
    "def correct_url(url): \n",
    "    if not url.startswith(\"http://\") and not url.startswith(\"https://\"):\n",
    "        url = \"http://\" + url\n",
    "    return url\n",
    "\n",
    "def crawl_url(url, run_headless=True):\n",
    "    if run_headless:\n",
    "        display = Display(visible=0, size=(1024, 768))\n",
    "        display.start()\n",
    "    \n",
    "    url = correct_url(url)\n",
    "    browser = webdriver.Firefox()\n",
    "    browser.get(url)\n",
    "    \n",
    "    inputUrl = browser.find_element_by_id(\"url\")\n",
    "    inputUrl.clear()\n",
    "    inputUrl.send_keys(\"www.foxnews.com\")\n",
    "    inputUrl.send_keysAndWait(Keys.RETURN)\n",
    "#     time.sleep(2)\n",
    "    realCalque = browser.find_element_by_id(\"real\")\n",
    "    assert str(1) in realCalque.get_attribute(\"style\")\n",
    "    \n",
    "    browser.quit()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    url = \"http://fakenewsai.com\"\n",
    "    crawl_url(url, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google\n"
     ]
    }
   ],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "from selenium import webdriver\n",
    "\n",
    "display = Display(visible=0, size=(800, 600))\n",
    "display.start()\n",
    "\n",
    "# now Firefox will run in a virtual display. \n",
    "# you will not see the browser.\n",
    "browser = webdriver.Firefox()\n",
    "browser.get('http://www.google.com')\n",
    "print(browser.title)\n",
    "browser.quit()\n",
    "\n",
    "display.stop();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(\"http://www.python.org\")\n",
    "assert \"Python\" in driver.title\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "elem.clear()\n",
    "elem.send_keys(\"pycon\")\n",
    "elem.send_keys(Keys.RETURN)\n",
    "assert \"No results found.\" not in driver.page_source\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
